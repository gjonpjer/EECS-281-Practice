You are given an array of points where points[i] = [x_i, y_i] represents a point on the Cartesian plane, as well as an integer
ğ‘˜. Implement a function that returns the ğ‘˜ closest points to the origin (0, 0). Note that the distance between any two points (ğ‘¥1,ğ‘¦1)and (ğ‘¥2,ğ‘¦2) on a Cartesian plane is equal to âˆš(ğ‘¥2 âˆ’ğ‘¥1)^2 + (ğ‘¦2 âˆ’ğ‘¦1)^2. You may return the solution in any order, and the points in the
solution are guaranteed to be unique. For example, given [[101, 183],[-203,280],[281,-370]] and ğ‘˜ = 2, you would return
[[101,183],[-203,280]] (in any order), since these are the two points that are closest to the origin.
std::vector<std::vector<int32_t>> k_closest_to_origin(
const std::vector<std::vector<int32_t>>& points, int32_t k);
Your solution should run in worst-case Î˜(ğ‘›log(ğ‘˜)) time and Î˜(ğ‘˜) auxiliary space, where ğ‘› is the number of points in the input vector.